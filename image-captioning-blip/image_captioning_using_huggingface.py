# -*- coding: utf-8 -*-
"""image_captioning_huggingface (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CqZGEP68u9A3Qq1wdu6DmYvqvMZpyfkT
"""

# Step 1: Install everything
!pip install transformers==4.38.2 torch==2.2.1 gradio==5.23.2 langchain==0.1.11 bs4==0.0.2 requests==2.31.0

# Step 2: Upload image
from google.colab import files
uploaded = files.upload()

# Step 3: Import all necessary libraries
from PIL import Image
from transformers import AutoProcessor, BlipForConditionalGeneration
import torch
import requests
from bs4 import BeautifulSoup
import langchain  # placeholder, not used in this script
import gradio as gr

# Step 4: Load BLIP model and processor
processor = AutoProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# Step 5: Set path of uploaded image
# Replace with actual filename if needed
img_path = list(uploaded.keys())[0]  # Automatically grab uploaded image name
image = Image.open(img_path).convert('RGB')

# Step 6: Generate caption
text = "the image of"
inputs = processor(images=image, text=text, return_tensors="pt")
outputs = model.generate(**inputs, max_length=50)
caption = processor.decode(outputs[0], skip_special_tokens=True)

# Step 7: Show caption
print("Caption:", caption)

import gradio as gr
from PIL import Image
from transformers import AutoProcessor, BlipForConditionalGeneration
import torch

# Load BLIP model and processor (do this only once)
processor = AutoProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# Define Gradio function
def generate_caption(image):
    text = "the image of"
    inputs = processor(images=image, text=text, return_tensors="pt")
    outputs = model.generate(**inputs, max_length=50)
    caption = processor.decode(outputs[0], skip_special_tokens=True)
    return caption

# Build the Gradio UI
gr.Interface(
    fn=generate_caption,
    inputs=gr.Image(type="pil", label="Upload Image"),
    outputs=gr.Text(label="Generated Caption"),
    title="BLIP Image Captioning",
    description="Upload an image to get a caption using Salesforce's BLIP model."
).launch(share=True)

import requests
from bs4 import BeautifulSoup
from PIL import Image
from io import BytesIO
import gradio as gr
from transformers import AutoProcessor, BlipForConditionalGeneration
import torch

# Load BLIP model and processor once
processor = AutoProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# Function to scrape, download, and caption images from a website
def caption_images_from_url(website_url):
    try:
        html = requests.get(website_url, timeout=10).text
    except Exception as e:
        return [["Error fetching site", str(e)]]

    soup = BeautifulSoup(html, "html.parser")
    img_tags = soup.find_all("img")
    img_urls = [img.get("src") for img in img_tags if img.get("src")]

    # Ensure valid absolute URLs
    def fix_url(url):
        if url.startswith("//"):
            return "https:" + url
        elif url.startswith("/"):
            return website_url.rstrip("/") + url
        elif not url.startswith("http"):
            return website_url.rstrip("/") + "/" + url
        return url

    img_urls = list(map(fix_url, img_urls))

    results = []
    for img_url in img_urls[:10]:  # limit to 10 images
        try:
            img_response = requests.get(img_url, timeout=5)
            image = Image.open(BytesIO(img_response.content)).convert("RGB")

            # Caption generation
            text = "the image of"
            inputs = processor(images=image, text=text, return_tensors="pt")
            outputs = model.generate(**inputs, max_length=50)
            caption = processor.decode(outputs[0], skip_special_tokens=True)

            results.append([image, caption])
        except Exception as e:
            print(f"‚ùå Skipped {img_url} due to: {e}")
            continue

    if not results:
        return [["No valid images found or all failed to caption"]]

    return results

# Gradio UI
gr.Interface(
    fn=caption_images_from_url,
    inputs=gr.Textbox(label="Enter Website URL"),
    outputs=gr.Gallery(label="Image Captions"),
    title="üñºÔ∏è Web Image Captioning with BLIP",
    description="Paste a website URL to extract and caption images using Hugging Face's BLIP model.",
    allow_flagging="never"
).launch()