# -*- coding: utf-8 -*-
"""gradiobasedmeetingtranscriber.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15ZWkx9gVuB2cUcrbj8hpqZ0D06F-yd2w
"""

# Step 1: Install dependencies (only needed once)
!pip install -q gradio transformers torchaudio

# Step 2: Import libraries
import gradio as gr
from transformers import pipeline

# Step 3: Load Whisper-small WITHOUT the 'language' parameter
asr = pipeline(
    task="automatic-speech-recognition",
    model="openai/whisper-small",
    chunk_length_s=30,
    return_timestamps=True
)

# Step 4: Define transcription function
def transcribe_audio(audio_file):
    result = asr(audio_file)
    return result["text"]

# Step 5: Build Gradio UI
interface = gr.Interface(
    fn=transcribe_audio,
    inputs=gr.Audio(type="filepath", label="üéß Upload Meeting Audio (MP3/WAV)"),
    outputs=gr.Textbox(label="üìù Transcription Output"),
    title="ü§ñ Shubham Singh ‚Äî AI-Based Static Meeting Transcriber",
    description="Upload a static meeting recording. This AI tool will transcribe it using OpenAI Whisper-small. Optimized for CPU.",
    theme="default"
)

# Step 6: Launch the app
interface.launch()