# -*- coding: utf-8 -*-
"""basic_AI_using_huggingface.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jHggpqrXPy2KuozoMyCgqXpym_isk5mh
"""

!pip install transformers==4.30.2 torch gradio

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import gradio as gr

model_name = "facebook/blenderbot-400M-distill"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

conversation_history = []

def chat(user_input):
    global conversation_history
    inputs = tokenizer(user_input, return_tensors="pt")
    outputs = model.generate(
        **inputs,
        max_new_tokens=50,
        repetition_penalty=1.2,
        do_sample=True,
        top_k=50,
        top_p=0.95
    )
    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
    conversation_history.append(user_input)
    conversation_history.append(response)
    return response

gr.Interface(fn=chat, inputs="text", outputs="text", title="Basic AI Chat Bot made by Shubham Singh").launch(share=True)